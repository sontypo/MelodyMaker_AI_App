{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ae8a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c1cafef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Dataset Class ======\n",
    "class GTZANMelDataset(Dataset):\n",
    "    def __init__(self, data_dir, genre_list, max_width=1024):\n",
    "        self.data = []\n",
    "        for label, genre in enumerate(genre_list):\n",
    "            folder = os.path.join(data_dir, genre)\n",
    "            for file in os.listdir(folder):\n",
    "                if file.endswith('.npy'):\n",
    "                    self.data.append((os.path.join(folder, file), label))\n",
    "        self.max_width = max_width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.data[idx]\n",
    "        mel = np.load(path)[:, :self.max_width]\n",
    "        mel = (mel + 80.0) / 80.0 * 2.0 - 1.0\n",
    "        mel = torch.tensor(mel, dtype=torch.float32).unsqueeze(0)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return mel, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e503c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Generator ======\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim=100, genre_dim=10):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(noise_dim + genre_dim, 512 * 4 * 8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, (2, 4), (2, 2), (0, 1)),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, (1, 4), (1, 4)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        x = torch.cat([z, labels], dim=1)\n",
    "        x = self.fc(x).view(-1, 512, 4, 8)\n",
    "        return self.deconv(x)[:, :, :128, :1024]\n",
    "\n",
    "# ====== Discriminator ======\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(11, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 1, 4, 2, 1),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(1 * 8 * 64, 1)\n",
    "\n",
    "    def forward(self, mel, labels):\n",
    "        B, _, H, W = mel.shape\n",
    "        label_map = labels.view(B, 10, 1, 1).expand(B, 10, H, W)\n",
    "        x = torch.cat([mel, label_map], dim=1)\n",
    "        x = self.model(x)\n",
    "        return self.fc(self.flatten(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f2f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | D Loss: 0.1533 | G Loss: 1.0065\n",
      "Epoch 2/30 | D Loss: 0.3901 | G Loss: 0.8367\n"
     ]
    }
   ],
   "source": [
    "# ====== Training Loop ======\n",
    "def train_gan():\n",
    "    genre_list = ['blues', 'classical', 'country', 'disco', 'hiphop',\n",
    "                    'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dataloader = DataLoader(GTZANMelDataset(r\"C:\\Users\\user\\OneDrive\\桌面\\游老師機器學習\\mel_spectrograms\" , genre_list), batch_size=16, shuffle=True)\n",
    "    G, D = Generator().to(device), Discriminator().to(device)\n",
    "    g_opt = optim.Adam(G.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "    d_opt = optim.Adam(D.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    g_losses, d_losses = [], []\n",
    "\n",
    "    for epoch in range(30):\n",
    "        for real_mel, label_idx in dataloader:\n",
    "            B = real_mel.size(0)\n",
    "            real_mel, label_idx = real_mel.to(device), label_idx.to(device)\n",
    "            labels = torch.eye(10)[label_idx].to(device)\n",
    "            real_out = D(real_mel, labels)\n",
    "\n",
    "            # Train Discriminator\n",
    "            z = torch.randn(B, 100).to(device)\n",
    "            fake_mel = G(z, labels).detach()\n",
    "            fake_out = D(fake_mel, labels)\n",
    "            d_loss = criterion(real_out, torch.ones_like(real_out)) + \\\n",
    "                    criterion(fake_out, torch.zeros_like(fake_out))\n",
    "            D.zero_grad(); d_loss.backward(); d_opt.step()\n",
    "\n",
    "            # Train Generator\n",
    "            fake_mel = G(z, labels)\n",
    "            fake_out = D(fake_mel, labels)\n",
    "            g_loss = criterion(fake_out, torch.ones_like(fake_out))\n",
    "            G.zero_grad(); g_loss.backward(); g_opt.step()\n",
    "\n",
    "        g_losses.append(g_loss.item())\n",
    "        d_losses.append(d_loss.item())\n",
    "        print(f\"Epoch {epoch+1}/30 | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
    "\n",
    "    torch.save(G.state_dict(), \"generator.pt\")\n",
    "    torch.save(D.state_dict(), \"discriminator.pt\")\n",
    "    np.save(\"g_losses.npy\", np.array(g_losses))\n",
    "    np.save(\"d_losses.npy\", np.array(d_losses))\n",
    "\n",
    "    plt.plot(g_losses, label='G Loss')\n",
    "    plt.plot(d_losses, label='D Loss')\n",
    "    plt.legend(); plt.grid(); plt.title(\"Loss Curve\")\n",
    "    plt.savefig(\"loss_curve.png\"); plt.show()\n",
    "    \n",
    "    G.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, 100).to(device)\n",
    "        sample_label = torch.tensor([[1.0 if i == 0 else 0.0 for i in range(10)]]).to(device)\n",
    "        fake_mel = G(z, sample_label)\n",
    "\n",
    "    fake_mel = fake_mel.squeeze().detach().cpu().numpy()\n",
    "    audio = librosa.feature.inverse.mel_to_audio(fake_mel, sr=22050, n_fft=2048, hop_length=512, win_length=2048, window='hann', power=2.0, n_iter=64)\n",
    "    audio = np.clip(audio, -1.0, 1.0).astype(np.float32)\n",
    "    if len(audio.shape) == 1:\n",
    "        audio = audio[:, np.newaxis]\n",
    "    sf.write(\"generated_audio_sample.wav\", audio, 22050)\n",
    "    print(\"✅ 已產生音訊並儲存為 generated_audio_sample.wav\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_gan()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
